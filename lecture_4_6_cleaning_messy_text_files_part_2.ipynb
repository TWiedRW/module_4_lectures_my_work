{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4.6 - Basics of cleaning messy text files \n",
    "## Part 2 - Grouping blocks of data and extracting information\n",
    "\n",
    "In this lecture, we will go over a number of cases of messy data, and how to use Python to fix these problems.  This includes\n",
    "\n",
    "1. Removing unwanted lines.\n",
    "2. Parsing lines with regular expressions.\n",
    "3. Working with data blocks spread across multiple lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in current progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('911_Deaths_Grouped.csv') as f:\n",
    "    content = f.read()\n",
    "content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_lines = content.split('\\n')\n",
    "grouped_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "Below I have transfered over the preprocessing functions and applied them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from composable import pipeable\n",
    "from composable.strict import map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "add_missing_period = pipeable(lambda line: line if line.endswith('.') else line + '.' )\n",
    "fix_world_trade = pipeable(lambda line: line.replace('WorldTrade', 'World Trade'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grouped_lines\n",
    ">> map(add_missing_period)\n",
    ">> map(fix_world_trade)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience I will give these a name\n",
    "prepped_lines = (grouped_lines \n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                )\n",
    "prepped_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular expression from lab 2\n",
    "\n",
    "Below I have attempted to combine all of the regular expressions from lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "line_parts = re.compile('^(.+), (\\?\\?|\\d{1,3}),(.*?)( Passenger,| Flight Crew,)?( United \\d{2,3},| American \\d{2,3},)?( World Trade Center| Pentagon| Shanksville, Pa)(, died \\d{1,2}/\\d{1,2}/\\d{1,2})?\\.$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_lines[2402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_parts.search(prepped_lines[2402]).groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Always check for non-matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(prepped_lines) if not line_parts.search(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbose regular expressions\n",
    "\n",
    "**Pros:**\n",
    "* Spread over multiple lines\n",
    "* Allow comments\n",
    "\n",
    "**Cons:**\n",
    "* Ignore white space outside `()`\n",
    "* Require escaping spaces `\\ `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Using VERBOSE \n",
    "regex_email = re.compile(r'^([a-z0-9_\\.-]+)@([0-9a-z\\.-]+)\\.([a-z\\.]{2, 6})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VERBOSE \n",
    "regex_email = re.compile(r\"\"\" \n",
    "                        ^([a-z0-9_\\.-]+)\t\t\t # local Part \n",
    "                        @\t\t\t\t\t\t\t # single @ sign \n",
    "                        ([0-9a-z\\.-]+)\t\t\t \t # Domain name \n",
    "                        \\.\t\t\t\t\t\t \t # single Dot . \n",
    "                        ([a-z]{2,6})$\t\t\t\t # Top level Domain \n",
    "                        \"\"\",re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example.\n",
    "\n",
    "This example, from the Python docs, shows how to space out an OR section across multiple lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charref = re.compile(r\"\"\"\n",
    " &[#]                # Start of a numeric entity reference\n",
    " (\n",
    "     0[0-7]+         # Octal form\n",
    "   | [0-9]+          # Decimal form\n",
    "   | x[0-9a-fA-F]+   # Hexadecimal form\n",
    " )\n",
    " ;                   # Trailing semicolon\n",
    "\"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up our regular expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.6.1 - Clean up the regular expression </font> </h2>\n",
    "\n",
    "To clean up the regular expression, \n",
    "\n",
    "1. Replace all spaces with `\\ ` or `\\s` (I prefer the second)\n",
    "2. Turn the string into a multi-line string.\n",
    "3. Spread the parts over many lines\n",
    "4. Add comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe the bug here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_parts = re.compile(r\"\"\"\n",
    "    ^(.+)\n",
    "    \\s(\\?\\?|\\d{1,3})\n",
    "    (.*?)\n",
    "    (\\Passenger,|\\sFlight Crew,)?\n",
    "    (\\sUnited\\s\\d{2,3},|\\sAmerican\\s\\d{2,3},)?\n",
    "    (\\sWorld\\sTrade\\sCenter|\\sPentagon|\\sShanksville, Pa)\n",
    "    (,\\sdied\\s\\d{1,2}/\\d{1,2}/\\d{1,2})?\\.$\n",
    "    \n",
    "    \"\"\", re.VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from composable import pipeable\n",
    "from composable.strict import map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg Ex for a line\n",
    "line_parts = re.compile(r'''^(.+),\n",
    "(\n",
    "      \\s\\?\\?                          # ??\n",
    "    | \\s\\d{1,3}                       # or age\n",
    "),\n",
    "(.*?)                                 # Includes hometown and \n",
    "(\n",
    "        \\sPassenger,                  # Optional flight status\n",
    "    |   \\sFlightsCrew,\n",
    ")?\n",
    "(\n",
    "      \\sUnited\\s\\d{2,3},              # Optional flight\n",
    "    | \\sAmericans\\d{2,3},\n",
    ")?\n",
    "(\n",
    "       \\sWorld\\sTrade\\sCenter         # Location\n",
    "    |  \\sPentagon\n",
    "    |  \\sShanksville,\\sPa\n",
    ")\n",
    "(\n",
    "    ,\\sdied\\s\\d{1,2}/\\d{1,2}/\\d{1,2}  # Optional date of death\n",
    ")?\n",
    "\\.$''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "add_missing_period = pipeable(lambda line: line if line.endswith('.') else line + '.' )\n",
    "fix_world_trade = pipeable(lambda line: line.replace('WorldTrade', 'World Trade'))\n",
    "# New\n",
    "get_line_parts = pipeable(lambda line: line_parts.search(line).groups(default=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(prepped_lines) if not line_parts.search(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines =  (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(get_line_parts)\n",
    "                )\n",
    "split_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling out and cleaning up names\n",
    "\n",
    "Sometimes it is useful to pull the various columns apart and clean them up separately.  To illustrate, will will pull out and clean up the names. We can do this using the `get` function from `toolz.curried` which *gets* the value from a list at a given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.curried import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(split_lines\n",
    ">> map(get(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clean up these name by removing commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_commas = lambda s: s.replace(',', '')\n",
    "\n",
    "(split_lines\n",
    ">> map(get(0))\n",
    ">> map(remove_commas)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling out and cleaning up ages\n",
    "\n",
    "NExt, we will pull out and clean the ages.  In this case, we should replace the missing values, currently `'??'`, to blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_quest_mark = lambda s: s.replace('??', '')\n",
    "\n",
    "(split_lines\n",
    ">> map(get(1))\n",
    ">> map(remove_quest_mark)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from composable import pipeable\n",
    "from composable.strict import map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg Ex for a line\n",
    "line_parts = re.compile(r'''^(.+),\n",
    "(\n",
    "      \\s\\?\\?                          # ??\n",
    "    | \\s\\d{1,3}                       # or age\n",
    "),\n",
    "(.*?)                                 # Includes hometown and \n",
    "(\n",
    "        \\sPassenger,                  # Optional flight status\n",
    "    |   \\sFlightsCrew,\n",
    ")?\n",
    "(\n",
    "      \\sUnited\\s\\d{2,3},              # Optional flight\n",
    "    | \\sAmericans\\d{2,3},\n",
    ")?\n",
    "(\n",
    "       \\sWorld\\sTrade\\sCenter         # Location\n",
    "    |  \\sPentagon\n",
    "    |  \\sShanksville,\\sPa\n",
    ")\n",
    "(\n",
    "    ,\\sdied\\s\\d{1,2}/\\d{1,2}/\\d{1,2}  # Optional date of death\n",
    ")?\n",
    "\\.$''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "add_missing_period = pipeable(lambda line: line if line.endswith('.') else line + '.' )\n",
    "fix_world_trade = pipeable(lambda line: line.replace('WorldTrade', 'World Trade'))\n",
    "get_line_parts = pipeable(lambda line: line_parts.search(line).groups(default=''))\n",
    "# New\n",
    "remove_commas = lambda s: s.replace(',', '')\n",
    "remove_quest_mark = lambda s: s.replace('??', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(prepped_lines) if not line_parts.search(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines =  (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(get_line_parts)\n",
    "                )\n",
    "split_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =  (split_lines\n",
    "        >> map(get(0))\n",
    "        >> map(remove_commas)\n",
    "        )\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ages =  (split_lines\n",
    "        >> map(get(1))\n",
    "        >> map(remove_quest_mark)\n",
    "        )\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.6.2 - Separating and cleaning other columns. </font> </h2>\n",
    "\n",
    "To clean up the following columns \n",
    "\n",
    "1. Grab the date of death and replace the missing values with `9/11/2001`\n",
    "2. Grab the locations (e.g. `World Trade Center`) and remove the comma from `'Shanksville, Pa.`\n",
    "3. Grab the flights.\n",
    "4. Grab the passenger status.\n",
    "\n",
    "**Note:** Be sure to strip whitespace from all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your fix here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the troubling bit\n",
    "\n",
    "We have made significant progress, but still need to work on the third entry, which contains the hometown and employment information.  Again, we can do this using the `get` function from `toolz.curried` which *gets* the value from a list at a given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "troubling_bit = (split_lines\n",
    "                >> map(get(2))\n",
    "                )\n",
    "troubling_bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progressively filtering out states\n",
    "\n",
    "We will start by matching two of the most common states, NY and NJ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = re.compile(', (N\\.Y\\.|N\\.J\\.),?')\n",
    "# Rows that match\n",
    "[(l, state.search(l)) for l in troubling_bit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and inspecting all rows that don't match for additional states or problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(troubling_bit) if not state.search(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing a common problem.\n",
    "\n",
    "Notice that many rows simply contain ` New York City,` without the state.  Let's fix this problem in our preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_lines[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_nyc = pipeable(lambda line: line.replace(', New York City,', ', New York City, N.Y.,'))\n",
    "grouped_lines[41] >> fix_nyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from composable import pipeable\n",
    "from composable.strict import map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg Ex for a line\n",
    "line_parts = re.compile(r'''^(.+),\n",
    "(\n",
    "      \\s\\?\\?                          # ??\n",
    "    | \\s\\d{1,3}                       # or age\n",
    "),\n",
    "(.*?)                                 # Includes hometown and \n",
    "(\n",
    "        \\sPassenger,                  # Optional flight status\n",
    "    |   \\sFlightsCrew,\n",
    ")?\n",
    "(\n",
    "      \\sUnited\\s\\d{2,3},              # Optional flight\n",
    "    | \\sAmericans\\d{2,3},\n",
    ")?\n",
    "(\n",
    "       \\sWorld\\sTrade\\sCenter         # Location\n",
    "    |  \\sPentagon\n",
    "    |  \\sShanksville,\\sPa\n",
    ")\n",
    "(\n",
    "    ,\\sdied\\s\\d{1,2}/\\d{1,2}/\\d{1,2}  # Optional date of death\n",
    ")?\n",
    "\\.$''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "add_missing_period = pipeable(lambda line: line if line.endswith('.') else line + '.' )\n",
    "fix_world_trade = pipeable(lambda line: line.replace('WorldTrade', 'World Trade'))\n",
    "get_line_parts = pipeable(lambda line: line_parts.search(line).groups(default=''))\n",
    "remove_commas = lambda s: s.replace(',', '')\n",
    "# New\n",
    "fix_nyc = pipeable(lambda line: line.replace(', New York City,', ', New York City, N.Y.,'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(prepped_lines) if not line_parts.search(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines =  (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(fix_nyc)\n",
    "                >> map(get_line_parts)\n",
    "                )\n",
    "split_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =  (split_lines\n",
    "        >> map(get(0))\n",
    "        >> map(remove_commas)\n",
    "        )\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "troubling_bit = (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(fix_nyc)\n",
    "                >> map(get_line_parts)\n",
    "                >> map(get(2))\n",
    "                )\n",
    "troubling_bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more states\n",
    "\n",
    "Next, we will start adding start to our pattern, and again looking for additional states/problems.  For example, let's add the `Mass.` and `D.C.` patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = re.compile(', (N\\.Y\\.|N\\.J\\.|Mass\\.|D\\.C\\.),?')\n",
    "[(l, state.search(l)) for l in troubling_bit if state.search(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(troubling_bit) if not state.search(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.6.2 - Continue the process. </font> </h2>\n",
    "\n",
    "Now it is your turn.  You should\n",
    "\n",
    "1. Keep adding states to the pattern.\n",
    "2. Add preprocessing steps to fix any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "state = re.compile(', (N\\.Y\\.|N\\.J\\.|Pa\\.|Mass\\.|D\\.C\\.|Ill\\.|Calif\\.|Md\\.|N\\.H\\.|Va\\.|Conn\\.|R\\.I\\.|N\\.C\\.|England|Ky\\.|Ga\\.),?')\n",
    "[(i, l) for i, l in enumerate(troubling_bit) if not state.search(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.6.3 - Make your solution verbose </font> </h2>\n",
    "\n",
    "Now make your solution to the last problem verbose.  Also reorder the cases so that similar cases are close and add comments.  Finally, change the regular expression to capture the parts before and after the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the troubling bit\n",
    "\n",
    "Now that we have a way to identify rows that have home addresses (through matching the state), we will split up this data.  We will do this by considering three cases.\n",
    "\n",
    "1. Blank entry become three blanks (for town, state, employer).\n",
    "2. Lines that match the states regex will get split by this pattern.\n",
    "3. The remaining lines hold only the employer and become `'','',entry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_troubling_bit(entry):\n",
    "    if len(entry) == 0:\n",
    "        return ('', '', '')\n",
    "    elif state.search(entry):\n",
    "        return state.search(entry).groups(default='')\n",
    "    else:\n",
    "        return ('', '', entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( troubling_bit\n",
    " >> map(split_troubling_bit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from composable import pipeable\n",
    "from composable.strict import map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg Ex for a line\n",
    "line_parts = re.compile(r'''^(.+),\n",
    "(\n",
    "      \\s\\?\\?                          # ??\n",
    "    | \\s\\d{1,3}                       # or age\n",
    "),\n",
    "(.*?)                                 # Includes hometown and \n",
    "(\n",
    "        \\sPassenger,                  # Optional flight status\n",
    "    |   \\sFlightsCrew,\n",
    ")?\n",
    "(\n",
    "      \\sUnited\\s\\d{2,3},              # Optional flight\n",
    "    | \\sAmericans\\d{2,3},\n",
    ")?\n",
    "(\n",
    "       \\sWorld\\sTrade\\sCenter         # Location\n",
    "    |  \\sPentagon\n",
    "    |  \\sShanksville,\\sPa\n",
    ")\n",
    "(\n",
    "    ,\\sdied\\s\\d{1,2}/\\d{1,2}/\\d{1,2}  # Optional date of death\n",
    ")?\n",
    "\\.$''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "add_missing_period = pipeable(lambda line: line if line.endswith('.') else line + '.' )\n",
    "fix_world_trade = pipeable(lambda line: line.replace('WorldTrade', 'World Trade'))\n",
    "get_line_parts = pipeable(lambda line: line_parts.search(line).groups(default=''))\n",
    "remove_commas = lambda s: s.replace(',', '')\n",
    "# New\n",
    "fix_nyc = pipeable(lambda line: line.replace(', New York City,', ', New York City, N.Y.,'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, l) for i, l in enumerate(prepped_lines) if not line_parts.search(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines =  (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(fix_nyc)\n",
    "                >> map(get_line_parts)\n",
    "                )\n",
    "split_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =  (split_lines\n",
    "        >> map(get(0))\n",
    "        >> map(remove_commas)\n",
    "        )\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "troubling_bit = (grouped_lines\n",
    "                >> map(add_missing_period)\n",
    "                >> map(fix_world_trade)\n",
    "                >> map(fix_nyc)\n",
    "                >> map(get_line_parts)\n",
    "                >> map(get(2))\n",
    "                )\n",
    "troubling_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = re.compile('''\n",
    "^(.*?)\n",
    ",?\\s                    # Optional comman\n",
    "(\n",
    "       N\\.Y\\.           \n",
    "    |  N\\.J\\.\n",
    "    |  D\\.C\\.\n",
    "    |  N\\.H\\.\n",
    "    |  N\\.M\\.\n",
    "    |  N\\.C\\.\n",
    "    |  R.I.\n",
    "    |  Md\\.\n",
    "    |  Pa\\.\n",
    "    |  Va\\.\n",
    "    |  Ga\\.\n",
    "    |  La\\.\n",
    "    |  Mass\\.\n",
    "    |  Calif\\.\n",
    "    |  Ariz\\.\n",
    "    |  Fla\\.\n",
    "    |  Ill\\.\n",
    "    |  Conn\\.\n",
    "    |  Hawaii\n",
    "    |  Iowa\n",
    "    |  Maine\n",
    "    |  New\\sHampshire\n",
    "    |  New\\sJersey\n",
    "    |  New\\sYork\n",
    "    |  Ohio\n",
    "    |  Pennsylvania\n",
    "    |  Texas\n",
    "    |  Utah\n",
    "    |  Virginia\n",
    "    |  Japan\n",
    "    |  India\n",
    "    |  Germany\n",
    "    |  Manitoba,\\sCanada\n",
    "    |  New\\sSouth\\sWales,\\sAustralia\n",
    "    |  England,\\sUnited\\sKingdom\n",
    ")\n",
    ",\n",
    "(.*?)$\n",
    "''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( troubling_bit\n",
    " >> map(split_troubling_bit)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.5.4 </font> </h2>\n",
    "\n",
    "Clean up each part of the troubling bits, then comma join this section into 1 string.\n",
    "\n",
    "**Hint:** Be sure to remove any problematic commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the parts back together.\n",
    "\n",
    "We can combine the parts back together using the `zip` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from composable.strict import zipOnto\n",
    "from composable.list import to_list\n",
    "(zip(names, ages, fixed_troubling_bits)\n",
    " >> to_list\n",
    " >> map(comma_join)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color=\"red\"> Exercise 4.5.4 </font> </h2>\n",
    "\n",
    "Use `zip` to combine all part of the data and write the result out to a file called `911_Deaths_Fixed.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
